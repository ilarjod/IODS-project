#Regression and model validation

*This week I learned about importing and wrangling data and simple analysis*



### Importing data

The data is from a survey from a Finnish introductory statistics course regarding learning.

I originally imported a dataset with 183 observations and 60 variables and manipulated it as advised into a tighter one, which I will be analysing now.

```{r warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(GGally)
lrn14 <- read.table("data/learning2014.txt")
str(lrn14)
summary(lrn14)
``` 

It now contains 166 observations and 7 variables. The variables are:
```
* gender      Man (56) or Female (110)
* age         Range 17-55, median 22.
* attitude    Measures attitude towards learning statistics
* deep        Deep learning
* stra        Strategic approach
* surf        Surface learning
* points      Points from exam
```



### Graphical overview
```{r warning=FALSE, message=FALSE}
ggpairs(lrn14, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))

```

The highest correlation to `points` seems to be with variable `attitude`.





### Fitting a regression model

Let's try to model `points ` with 3 variables. I choose `age`, `attitude` and `stra`.

```{r warning=FALSE, message=FALSE}
model1 <- lm(points ~ age + attitude + stra, data = lrn14)
summary(model1)
```

Only `attitude`  seems to be correlated enough (other are P<0.1, attitude p<0.001), so let's dump the other two from the model.

```{r warning=FALSE, message=FALSE}
model2 <- lm(points ~ attitude , data = lrn14)
summary(model2)
```

R-squared: the percentage of the response variable variation that is explained by a linear model.  

So `attitude` is a statistically significant variable. It explains ~19% of the variability in `points`. 

Let's visualize the model.

```{r warning=FALSE, message=FALSE}
qplot(attitude, points, data = lrn14) + geom_smooth(method = "lm")
```




### Model diagnostics

When fitting  linear model, we are assuming:

* The errors are normally distributed
* The errors are not correlated
* The errors have constant variance
* The size of a given error does not depend on the explanatory variables

We can evaluate the assumptions by examining how the residuals behave. 

```{r warning=FALSE, message=FALSE}
par(mfrow = c(2,2))
plot(model2, which = c(1,2,5)) 
```

There is no pattern in the vs fitted plot and in the Q-Q plot the residuals are on the line, which means the residuals are normally distributed. There are no significant outliers in the residuals vs leverage plot so our model assumptions are ok.

### Conclusion

Positive attitude gives you more points!

